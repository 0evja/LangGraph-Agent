"""
ä»»åŠ¡:åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯¹è¯å¼æ•°æ®åˆ†æAgent
ä»¥å¼€æºå¤§æ¨¡å‹Llama3.1:8bä¸ºæ ¸å¿ƒ,é€šè¿‡Ollamaå®ç°æœ¬åœ°åŒ–éƒ¨ç½²,ç»“åˆLangChainå’ŒLangGraphæ¡†æ¶æ„å»ºè‡ªç„¶è¯­è¨€äº¤äº’Agent.
æ”¯æŒç”¨æˆ·é€šè¿‡å¯¹è¯å½¢å¼æŸ¥è¯¢å’Œåˆ†ææœ¬åœ°æ•°æ®åº“ï¼Œè¿˜å…è®¸ç”¨æˆ·ä¸Šä¼ è‡ªå®šä¹‰ä¸šåŠ¡èƒŒæ™¯æè¿°åŠæ•°æ®é›†ï¼Œæ‰©å±•é€‰æ‹©å…¶ä»–ä¸šåŠ¡åœºæ™¯ã€‚
è®¾è®¡åŠ¨æ€æ•°æ®å¯è§†åŒ–æ¨¡å—,åˆ©ç”¨Streamlitå®ç°å‰ç«¯å›¾è¡¨æ¸²æŸ“,æ”¯æŒå¤šç»´åº¦æ•°æ®å±•ç¤ºä¸äº¤äº’å¼åˆ†æ.
åŒæ—¶é€šè¿‡æŒç»­å¯¹è¯ä¼˜åŒ–åˆ†ææµç¨‹ï¼Œå®ç°äººæœºåä½œçš„é«˜æ•ˆæ•°æ®å¤„ç†ã€‚
ç›®å‰å·²ç»åœ¨Agent.pyæ–‡ä»¶ä¸­ä½¿ç”¨LangGraphå®ç°Agentçš„åŸºæœ¬æ¡†æ¶, å¹¶åœ¨app.pyæ–‡ä»¶ä¸­ä½¿ç”¨streamlitå®ç°çš„å‰ç«¯çš„è®¾è®¡,
è¦æ±‚åœ¨Agent.pyçš„åŸºç¡€ä¸Šå¢åŠ æ£€ç´¢æœ¬åœ°æ•°æ®åº“çš„åŠŸèƒ½, ä¿ç•™Tavilyå·¥å…·, å°†æ•°æ®æ£€ç´¢åŠŸèƒ½å®šä¹‰ä¸ºæ–°çš„å·¥å…·ã€‚
æœ¬åœ°æ•°æ®åœ¨é¡¹ç›®æ ¹ç›®å½•dataä¸‹, dataç›®å½•ä¸‹åŒ…å«ä»…txt.csvæ–‡ä»¶, ç»™å‡ºå®Œæ•´çš„Agent.pyæ–‡ä»¶ã€‚
æ³¨æ„:from langgraph.prebuilt.tool_executor import ToolExecutor å·²ç»ä¸å­˜åœ¨
"""


# app_frontend.py
import streamlit as st
from Agent import graph, State, MemorySaver  # å¯¼å…¥åŸå§‹ä¸šåŠ¡é€»è¾‘
from langchain_core.messages import AIMessage, HumanMessage
import uuid

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹",
    page_icon="ğŸ”",
    layout="centered",
    initial_sidebar_state="expanded"
)

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®è®¾ç½®")
    
    # ä¼šè¯ç®¡ç†
    st.subheader("ä¼šè¯ç®¡ç†")
    if st.button("æ–°å»ºä¼šè¯"):
        st.session_state.clear()
    
    # æ¨¡å‹è®¾ç½®
    st.subheader("æ¨¡å‹è®¾ç½®")
    ollama_model = st.selectbox(
        "é€‰æ‹©AIæ¨¡å‹",
        ["llama3.1:8b", "llama2", "mistral"],
        index=0,
        help="é€‰æ‹©ä½¿ç”¨çš„Ollamaæ¨¡å‹"
    )
    
    # é«˜çº§è®¾ç½®
    st.subheader("é«˜çº§è®¾ç½®")
    max_results = st.slider("æœ€å¤§æœç´¢ç»“æœ", 1, 5, 2)
    temperature = st.slider("æ¨¡å‹æ¸©åº¦", 0.0, 1.0, 0.7)
    stream_mode = st.checkbox("å¯ç”¨å®æ—¶æµå¼ä¼ è¾“", True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

# ä¸»ç•Œé¢å¸ƒå±€
st.title("ğŸ” æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹")
st.caption("ä½¿ç”¨LangGraphå’ŒOllamaæ„å»ºçš„æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹ï¼Œæ”¯æŒå®æ—¶ç½‘ç»œæœç´¢")

# æ˜¾ç¤ºèŠå¤©è®°å½•
for msg in st.session_state.messages:
    role = "AI" if isinstance(msg, AIMessage) else "ç”¨æˆ·"
    with st.chat_message(role):
        st.markdown(msg.content)
        if hasattr(msg, "additional_info"):
            st.json(msg.additional_info)

# ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜"):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    user_msg = HumanMessage(content=prompt)
    st.session_state.messages.append(user_msg)
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # å‡†å¤‡AIå“åº”åŒºåŸŸ
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        # æ„å»ºé…ç½®
        config = {
            "configurable": {
                "thread_id": st.session_state.thread_id,
                "model_settings": {
                    "temperature": temperature,
                    "max_results": max_results
                }
            }
        }
        
        # è¿è¡Œå¤„ç†æµç¨‹
        try:
            events = graph.stream(
                {"messages": [user_msg]},
                config=config,
                stream_mode="values" if stream_mode else "updates"
            )
            
            # å¤„ç†å®æ—¶äº‹ä»¶
            for event in events:
                if "messages" in event:
                    latest_msg = event["messages"][-1]
                    full_response += latest_msg.content + " "
                    
                    # æ›´æ–°å®æ—¶æ˜¾ç¤º
                    response_placeholder.markdown(full_response + "â–Œ")
                    
                    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                    if hasattr(latest_msg, "tool_calls"):
                        with st.expander("æŸ¥çœ‹ç ”ç©¶è¿‡ç¨‹"):
                            for tool_call in latest_msg.tool_calls:
                                st.write(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}")
                                st.json(tool_call["args"])
            
            # æœ€ç»ˆæ˜¾ç¤ºå®Œæ•´å“åº”
            response_placeholder.markdown(full_response)
            
            # ä¿å­˜AIæ¶ˆæ¯
            ai_msg = AIMessage(content=full_response)
            st.session_state.messages.append(ai_msg)
            
        except Exception as e:
            st.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

# ä¾§è¾¹æ åº•éƒ¨ä¿¡æ¯
with st.sidebar:
    st.divider()
    st.markdown("""
    **åŠŸèƒ½ç‰¹æ€§ï¼š**
    - å¤šæ¨¡å‹æ”¯æŒ
    - å®æ—¶ç½‘ç»œç ”ç©¶
    - å¯¹è¯å†å²ç®¡ç†
    - å¯è°ƒèŠ‚å‚æ•°é…ç½®
    """)